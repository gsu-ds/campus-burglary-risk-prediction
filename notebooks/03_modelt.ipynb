{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff92c23c",
   "metadata": {},
   "source": [
    "# 03 - Model T: Standardized Crime Prediction Pipeline\n",
    "\n",
    "> **\"Any model you want, as long as it's properly cross-validated.\"** \n",
    "> *‚Äî Henry Ford (probably)*\n",
    "\n",
    "**Purpose:** Mass-produce model evaluations with a standardized, efficient pipeline\n",
    "\n",
    "**Input:** \n",
    "- `data/processed/apd/target_crimes.csv`\n",
    "\n",
    "**Output:** \n",
    "- `data/processed/apd/cv_results/*_cv_metrics.csv` (performance summaries)\n",
    "- `data/processed/apd/cv_results/predictions/*.csv` (out-of-sample predictions)\n",
    "- `models/*.pkl` (trained model artifacts)\n",
    "\n",
    "**The Assembly Line (Rolling CV):**\n",
    "```\n",
    "Raw Data ‚Üí Feature Prep ‚Üí Train/Test Split ‚Üí Model Fit ‚Üí Predict ‚Üí Evaluate ‚Üí Repeat\n",
    "                             ‚Üë_______________|_________________________|\n",
    "                                          (4 Folds)\n",
    "```\n",
    "\n",
    "**Models on the Line:**\n",
    "1. ‚öôÔ∏è Baseline Models (Quality Control)\n",
    "   - Seasonal Naive (1-day, 7-day)\n",
    "   - Historical Mean (30-day)\n",
    "\n",
    "2. üöÄ Production Models\n",
    "   - XGBoost (Poisson objective)\n",
    "   - CatBoost (Poisson loss)\n",
    "   - LightGBM (Poisson objective)\n",
    "   - Zero-Inflated Poisson (ZIP) - if needed\n",
    "\n",
    "**Quality Metrics:**\n",
    "- MAE (Mean Absolute Error)\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- R¬≤ (Coefficient of Determination)\n",
    "- MAPE (Mean Absolute Percentage Error)\n",
    "\n",
    "**Timeline:** 4-fold rolling origin (2022 H1 ‚Üí 2022 H2 ‚Üí 2023 H1 ‚Üí 2023 H2)\n",
    "\n",
    "**Team:** Run this after `02_explorer.ipynb` to evaluate model performance\n",
    "\n",
    "**Runtime:** ~15-30 minutes (with hyperparameter tuning)\n",
    "**Est. Completion:** 1913 (or whenever your laptop finishes) üï∞Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983baad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports =================================================================\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "from rich import print as rprint\n",
    "\n",
    "# Initialize console\n",
    "console = Console()\n",
    "\n",
    "console.print(\n",
    "    Panel.fit(\n",
    "        \"Libraries imported successfully for modeling.\\n\\n\"\n",
    "        \"Ready to:\\n\"\n",
    "        \"- Build baseline models\\n\"\n",
    "        \"- Train ML models (XGBoost, CatBoost, LightGBM)\\n\"\n",
    "        \"- Perform rolling cross-validation\\n\"\n",
    "        \"- Evaluate and compare performance\",\n",
    "        title=\"03 Model T - Imports Complete\",\n",
    "        border_style=\"cyan\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef59fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===========================================================\n",
    "DATA_DIR = Path(\"../data\")\n",
    "PROCESSED_DATA_FOLDER = DATA_DIR / \"processed\" / \"apd\"\n",
    "MODELS_DIR = Path(\"../models\")\n",
    "\n",
    "# Create models directory\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "console.print(\n",
    "    Panel.fit(\n",
    "        \"[bold cyan]Paths configured.[/bold cyan]\\n\\n\"\n",
    "        f\"Data: [yellow]{PROCESSED_DATA_FOLDER}[/yellow]\\n\"\n",
    "        f\"Models: [yellow]{MODELS_DIR}[/yellow]\",\n",
    "        title=\"Configuration\",\n",
    "        border_style=\"cyan\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e619a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Pipeline Logging ========================================================\n",
    "pipeline_log: List[Dict[str, Any]] = []\n",
    "\n",
    "def log_step(step_name: str, df: pd.DataFrame) -> None:\n",
    "    \"\"\"Record a pipeline step with shape info.\"\"\"\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        rows_val = \"N/A\"\n",
    "        cols_val = \"N/A\"\n",
    "        rows_str = rows_val\n",
    "        cols_str = cols_val\n",
    "    else:\n",
    "        rows_val = int(df.shape[0])\n",
    "        cols_val = int(df.shape[1])\n",
    "        rows_str = f\"{rows_val:,}\"\n",
    "        cols_str = str(cols_val)\n",
    "\n",
    "    pipeline_log.append({\"step\": step_name, \"rows\": rows_val, \"cols\": cols_val})\n",
    "    console.print(f\"[green]‚úì {step_name}[/green] [cyan]‚Üí shape: {rows_str} x {cols_str}[/cyan]\")\n",
    "\n",
    "def show_pipeline_table() -> None:\n",
    "    \"\"\"Display a Rich table summarizing all steps.\"\"\"\n",
    "    if not pipeline_log:\n",
    "        console.print(\"[red]No steps logged yet.[/red]\")\n",
    "        return\n",
    "\n",
    "    table = Table(title=\"üìä Model T Pipeline Summary\", show_lines=True)\n",
    "    table.add_column(\"Step\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Rows\", style=\"green\")\n",
    "    table.add_column(\"Cols\", style=\"yellow\")\n",
    "\n",
    "    for entry in pipeline_log:\n",
    "        rows_val = entry['rows']\n",
    "        cols_val = entry['cols']\n",
    "        rows_str = f\"{rows_val:,}\" if isinstance(rows_val, int) else str(rows_val)\n",
    "        cols_str = str(cols_val) if isinstance(cols_val, int) else str(cols_val)\n",
    "        table.add_row(entry[\"step\"], rows_str, cols_str)\n",
    "    \n",
    "    console.print(table)\n",
    "\n",
    "console.print(Panel(\"[bold green]Logger configured.[/bold green]\", border_style=\"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05420016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Processed Data =====================================================\n",
    "console.print(Panel(\"[bold cyan]Loading processed crime data...[/bold cyan]\", border_style=\"cyan\"))\n",
    "\n",
    "INPUT_PATH = PROCESSED_DATA_FOLDER / \"target_crimes.csv\"\n",
    "\n",
    "if not INPUT_PATH.exists():\n",
    "    console.print(f\"[bold red]ERROR:[/bold red] File not found: {INPUT_PATH}\")\n",
    "    console.print(\"[yellow]Please run 01_wrangler.ipynb first![/yellow]\")\n",
    "    raise FileNotFoundError(f\"Required file missing: {INPUT_PATH}\")\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "df['report_date'] = pd.to_datetime(df['report_date'])\n",
    "\n",
    "log_step(\"Step 0: Loaded processed data\", df)\n",
    "\n",
    "console.print(\n",
    "    Panel.fit(\n",
    "        f\"[bold green]‚úì Data loaded successfully![/bold green]\\n\\n\"\n",
    "        f\"Records: [cyan]{len(df):,}[/cyan]\\n\"\n",
    "        f\"Columns: [cyan]{len(df.columns)}[/cyan]\\n\"\n",
    "        f\"Date range: [cyan]{df['report_date'].min().date()} to {df['report_date'].max().date()}[/cyan]\",\n",
    "        title=\"Data Summary\",\n",
    "        border_style=\"green\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03611d",
   "metadata": {},
   "source": [
    "## üè≠ Section 1: The Factory Floor (Setup)\n",
    "Setting up our production line..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa31f3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "console.print(\n",
    "    Panel(\n",
    "        \"[bold magenta]STEP 1: Define modeling utilities for time-series cross-validation[/bold magenta]\",\n",
    "        border_style=\"magenta\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define output directories for CV results\n",
    "CV_RESULTS_DIR = PROCESSED_DATA_FOLDER / \"cv_results\"\n",
    "CV_FOLDS_DIR = CV_RESULTS_DIR / \"folds\"\n",
    "CV_PREDICTIONS_DIR = CV_RESULTS_DIR / \"predictions\"\n",
    "\n",
    "# Create directories\n",
    "CV_RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CV_FOLDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CV_PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "console.print(\n",
    "    f\"[green]‚úì CV output directories created:[/green]\\n\"\n",
    "    f\"  Results: {CV_RESULTS_DIR}\\n\"\n",
    "    f\"  Folds: {CV_FOLDS_DIR}\\n\"\n",
    "    f\"  Predictions: {CV_PREDICTIONS_DIR}\"\n",
    ")\n",
    "\n",
    "\n",
    "def run_rolling_cv(\n",
    "    model, \n",
    "    df, \n",
    "    target_col='crime_count', \n",
    "    date_col='report_date',\n",
    "    feature_cols=None,\n",
    "    group_col='npu',\n",
    "    save_outputs=True,\n",
    "    model_name=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs Rolling Origin Cross-Validation on Panel Data with auto-save.\n",
    "    \n",
    "    Args:\n",
    "        model: The initialized model (e.g., XGBRegressor, CatBoostRegressor)\n",
    "        df: The full dataframe (Must contain date_col, group_col, features)\n",
    "        target_col: Name of the target variable\n",
    "        date_col: Name of the date column\n",
    "        feature_cols: List of feature columns (if None, auto-detect)\n",
    "        group_col: Column for grouping (NPU, zone, etc.)\n",
    "        save_outputs: If True, saves train/test splits and predictions to CSV\n",
    "        model_name: Name for output files (defaults to model class name)\n",
    "    \n",
    "    Returns:\n",
    "        metrics_df: A dataframe showing MAE/RMSE/R¬≤ for each fold\n",
    "        predictions_df: Out-of-sample predictions for all folds\n",
    "        \n",
    "    Saves:\n",
    "        - {CV_FOLDS_DIR}/{model_name}_fold{i}_train.csv\n",
    "        - {CV_FOLDS_DIR}/{model_name}_fold{i}_test.csv\n",
    "        - {CV_PREDICTIONS_DIR}/{model_name}_all_predictions.csv\n",
    "        - {CV_RESULTS_DIR}/{model_name}_cv_metrics.csv\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine model name for file outputs\n",
    "    if model_name is None:\n",
    "        model_name = model.__class__.__name__ if hasattr(model, '__class__') else str(model)\n",
    "    \n",
    "    # Clean model name for filenames\n",
    "    model_name = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    \n",
    "    # 1. Prepare aggregated data if needed\n",
    "    console.print(f\"[cyan]Preparing data for rolling CV ({model_name})...[/cyan]\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # If target_col doesn't exist, create aggregated crime counts\n",
    "    if target_col not in df.columns:\n",
    "        console.print(f\"[yellow]Creating aggregated {target_col} by {group_col}...[/yellow]\")\n",
    "        df['date_only'] = df[date_col].dt.date\n",
    "        \n",
    "        # Aggregate to daily level by group\n",
    "        agg_df = df.groupby([group_col, 'date_only']).size().reset_index(name=target_col)\n",
    "        agg_df = agg_df.rename(columns={'date_only': date_col})\n",
    "        df = agg_df\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # 2. Define Timeline Cutoffs\n",
    "    folds = [\n",
    "        ('2022-01-01', '2022-07-01'),  # Fold 1: Test H1 2022\n",
    "        ('2022-07-01', '2023-01-01'),  # Fold 2: Test H2 2022\n",
    "        ('2023-01-01', '2023-07-01'),  # Fold 3: Test H1 2023\n",
    "        ('2023-07-01', '2024-01-01'),  # Fold 4: Test H2 2023\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    console.print(f\"[bold cyan]Starting Rolling CV for {model_name}...[/bold cyan]\")\n",
    "    \n",
    "    for i, (train_end, test_end) in enumerate(folds):\n",
    "        fold_num = i + 1\n",
    "        fold_name = f\"Fold {fold_num}\"\n",
    "        \n",
    "        # 3. Create Time-Based Splits\n",
    "        train_mask = df[date_col] < train_end\n",
    "        test_mask = (df[date_col] >= train_end) & (df[date_col] < test_end)\n",
    "        \n",
    "        train_data = df[train_mask].copy()\n",
    "        test_data = df[test_mask].copy()\n",
    "        \n",
    "        if len(test_data) == 0:\n",
    "            console.print(f\"[yellow]  {fold_name}: No test data, skipping.[/yellow]\")\n",
    "            continue\n",
    "        \n",
    "        # 4. Save train/test splits if requested\n",
    "        if save_outputs:\n",
    "            train_path = CV_FOLDS_DIR / f\"{model_name}_fold{fold_num}_train.csv\"\n",
    "            test_path = CV_FOLDS_DIR / f\"{model_name}_fold{fold_num}_test.csv\"\n",
    "            \n",
    "            train_data.to_csv(train_path, index=False)\n",
    "            test_data.to_csv(test_path, index=False)\n",
    "            \n",
    "            console.print(f\"[dim cyan]    Saved: {train_path.name} ({len(train_data):,} rows)[/dim cyan]\")\n",
    "            console.print(f\"[dim cyan]    Saved: {test_path.name} ({len(test_data):,} rows)[/dim cyan]\")\n",
    "        \n",
    "        # 5. Prepare Features\n",
    "        if feature_cols is None:\n",
    "            # Auto-detect: drop non-feature columns\n",
    "            drop_cols = [target_col, date_col, 'date_only', group_col, 'geometry']\n",
    "            drop_cols = [c for c in drop_cols if c in train_data.columns]\n",
    "            feature_cols = [c for c in train_data.columns if c not in drop_cols]\n",
    "        \n",
    "        X_train = train_data[feature_cols]\n",
    "        y_train = train_data[target_col]\n",
    "        X_test = test_data[feature_cols]\n",
    "        y_test = test_data[target_col]\n",
    "        \n",
    "        # 6. Train & Predict\n",
    "        if hasattr(model, 'fit'):\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_test)\n",
    "        else:\n",
    "            # Handle baseline models (custom predict signature)\n",
    "            preds = model.predict(test_data, train_data)\n",
    "        \n",
    "        # 7. Calculate Metrics\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "        r2 = r2_score(y_test, preds)\n",
    "        \n",
    "        # Additional metrics\n",
    "        mape = np.mean(np.abs((y_test - preds) / (y_test + 1e-10))) * 100\n",
    "        \n",
    "        console.print(\n",
    "            f\"[green]  {fold_name} ({train_end} to {test_end}):[/green] \"\n",
    "            f\"MAE={mae:.4f}, RMSE={rmse:.4f}, R¬≤={r2:.4f}, MAPE={mape:.2f}%\"\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'Fold': fold_name,\n",
    "            'Fold_Number': fold_num,\n",
    "            'Train_End': train_end,\n",
    "            'Test_End': test_end,\n",
    "            'Train_Size': len(train_data),\n",
    "            'Test_Size': len(test_data),\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R¬≤': r2,\n",
    "            'MAPE': mape\n",
    "        })\n",
    "        \n",
    "        # Store predictions for analysis\n",
    "        pred_df = test_data[[date_col, group_col, target_col]].copy()\n",
    "        pred_df['predicted'] = preds\n",
    "        pred_df['residual'] = y_test.values - preds\n",
    "        pred_df['abs_error'] = np.abs(pred_df['residual'])\n",
    "        pred_df['fold'] = fold_name\n",
    "        pred_df['fold_number'] = fold_num\n",
    "        all_predictions.append(pred_df)\n",
    "    \n",
    "    # 8. Compile results\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    predictions_df = pd.concat(all_predictions, ignore_index=True) if all_predictions else pd.DataFrame()\n",
    "    \n",
    "    # 9. Save summary outputs\n",
    "    if save_outputs and len(metrics_df) > 0:\n",
    "        metrics_path = CV_RESULTS_DIR / f\"{model_name}_cv_metrics.csv\"\n",
    "        metrics_df.to_csv(metrics_path, index=False)\n",
    "        console.print(f\"[bold green]  ‚úì Saved metrics: {metrics_path.name}[/bold green]\")\n",
    "        \n",
    "        if len(predictions_df) > 0:\n",
    "            predictions_path = CV_PREDICTIONS_DIR / f\"{model_name}_all_predictions.csv\"\n",
    "            predictions_df.to_csv(predictions_path, index=False)\n",
    "            console.print(f\"[bold green]  ‚úì Saved predictions: {predictions_path.name}[/bold green]\")\n",
    "    \n",
    "    # 10. Summary statistics\n",
    "    console.print(\"\\n[bold green]Cross-Validation Summary:[/bold green]\")\n",
    "    summary_table = Table(title=f\"{model_name} - CV Performance\", show_header=True)\n",
    "    summary_table.add_column(\"Metric\", style=\"cyan\")\n",
    "    summary_table.add_column(\"Mean\", style=\"green\")\n",
    "    summary_table.add_column(\"Std\", style=\"yellow\")\n",
    "    summary_table.add_column(\"Min\", style=\"red\")\n",
    "    summary_table.add_column(\"Max\", style=\"magenta\")\n",
    "    \n",
    "    for metric in ['MAE', 'RMSE', 'R¬≤', 'MAPE']:\n",
    "        mean_val = metrics_df[metric].mean()\n",
    "        std_val = metrics_df[metric].std()\n",
    "        min_val = metrics_df[metric].min()\n",
    "        max_val = metrics_df[metric].max()\n",
    "        \n",
    "        if metric == 'MAPE':\n",
    "            summary_table.add_row(\n",
    "                metric, \n",
    "                f\"{mean_val:.2f}%\", \n",
    "                f\"¬±{std_val:.2f}%\",\n",
    "                f\"{min_val:.2f}%\",\n",
    "                f\"{max_val:.2f}%\"\n",
    "            )\n",
    "        else:\n",
    "            summary_table.add_row(\n",
    "                metric, \n",
    "                f\"{mean_val:.4f}\", \n",
    "                f\"¬±{std_val:.4f}\",\n",
    "                f\"{min_val:.4f}\",\n",
    "                f\"{max_val:.4f}\"\n",
    "            )\n",
    "    \n",
    "    console.print(summary_table)\n",
    "    \n",
    "    return metrics_df, predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1297d99",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Section 2: Quality Control (Baseline Models)\n",
    "Before we build fancy models, let's establish minimum standards..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Models (Seasonal Naive)\n",
    "class SeasonalNaive:\n",
    "    \"\"\"Baseline: Uses last period's value as prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, period=7):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            period: Seasonality period (7 for weekly, 1 for daily)\n",
    "        \"\"\"\n",
    "        self.period = period\n",
    "        self.name = f\"Seasonal_Naive_{period}d\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "    \n",
    "    def predict(self, test_data, train_data):\n",
    "        \"\"\"Predict using last period's values.\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for idx, row in test_data.iterrows():\n",
    "            target_date = row['report_date'] - pd.Timedelta(days=self.period)\n",
    "            \n",
    "            # Find matching historical record\n",
    "            match = train_data[\n",
    "                (train_data['report_date'] == target_date) & \n",
    "                (train_data['npu'] == row['npu'])\n",
    "            ]\n",
    "            \n",
    "            if len(match) > 0:\n",
    "                predictions.append(match['crime_count'].iloc[0])\n",
    "            else:\n",
    "                # Fallback to overall mean if no match\n",
    "                predictions.append(train_data['crime_count'].mean())\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "class HistoricalMean:\n",
    "    \"\"\"Baseline: Uses historical mean by group.\"\"\"\n",
    "    \n",
    "    def __init__(self, window_days=30):\n",
    "        self.window_days = window_days\n",
    "        self.name = f\"Historical_Mean_{window_days}d\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "    \n",
    "    def predict(self, test_data, train_data):\n",
    "        \"\"\"Predict using historical mean.\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for idx, row in test_data.iterrows():\n",
    "            # Calculate mean from last N days in training data\n",
    "            cutoff_date = row['report_date'] - pd.Timedelta(days=self.window_days)\n",
    "            \n",
    "            historical = train_data[\n",
    "                (train_data['report_date'] >= cutoff_date) &\n",
    "                (train_data['npu'] == row['npu'])\n",
    "            ]\n",
    "            \n",
    "            if len(historical) > 0:\n",
    "                predictions.append(historical['crime_count'].mean())\n",
    "            else:\n",
    "                predictions.append(train_data['crime_count'].mean())\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "console.print(\"[green]‚úì Rolling CV utilities and baseline models defined.[/green]\")\n",
    "console.print(f\"[cyan]Output structure:[/cyan]\\n\"\n",
    "             f\"  üìÅ {CV_RESULTS_DIR.relative_to(DATA_DIR)}/\\n\"\n",
    "             f\"    ‚îú‚îÄ üìä [model_name]_cv_metrics.csv\\n\"\n",
    "             f\"    ‚îú‚îÄ üìÅ folds/\\n\"\n",
    "             f\"    ‚îÇ   ‚îú‚îÄ [model_name]_fold1_train.csv\\n\"\n",
    "             f\"    ‚îÇ   ‚îú‚îÄ [model_name]_fold1_test.csv\\n\"\n",
    "             f\"    ‚îÇ   ‚îî‚îÄ ... (8 files per model)\\n\"\n",
    "             f\"    ‚îî‚îÄ üìÅ predictions/\\n\"\n",
    "             f\"        ‚îî‚îÄ [model_name]_all_predictions.csv\")\n",
    "\n",
    "log_step(\"Step 1: Modeling utilities with auto-save functionality\", pd.DataFrame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0564a",
   "metadata": {},
   "source": [
    "### üìñ For Data Science Team: Accessing CV Results\n",
    "\n",
    "**Location:** `data/processed/apd/cv_results/`\n",
    "\n",
    "**Quick Access:**\n",
    "```python\n",
    "# Load summary metrics for a model\n",
    "xgb_metrics = pd.read_csv('data/processed/apd/cv_results/XGBRegressor_cv_metrics.csv')\n",
    "\n",
    "# Load predictions for error analysis\n",
    "xgb_preds = pd.read_csv('data/processed/apd/cv_results/predictions/XGBRegressor_all_predictions.csv')\n",
    "\n",
    "# Load specific fold data\n",
    "fold1_train = pd.read_csv('data/processed/apd/cv_results/folds/XGBRegressor_fold1_train.csv')\n",
    "fold1_test = pd.read_csv('data/processed/apd/cv_results/folds/XGBRegressor_fold1_test.csv')\n",
    "```\n",
    "\n",
    "**Compare all models:**\n",
    "```python\n",
    "import glob\n",
    "\n",
    "# Load all CV metrics\n",
    "metrics_files = glob.glob('data/processed/apd/cv_results/*_cv_metrics.csv')\n",
    "all_metrics = []\n",
    "\n",
    "for file in metrics_files:\n",
    "    df_temp = pd.read_csv(file)\n",
    "    model_name = Path(file).stem.replace('_cv_metrics', '')\n",
    "    df_temp['Model'] = model_name\n",
    "    all_metrics.append(df_temp)\n",
    "\n",
    "comparison = pd.concat(all_metrics, ignore_index=True)\n",
    "print(comparison.groupby('Model')[['MAE', 'RMSE', 'R¬≤']].mean().sort_values('MAE'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405b87f",
   "metadata": {},
   "source": [
    "## üöÄ Section 3: The Production Line (Ready to Run Models)\n",
    "\n",
    "**Your models are ready to run!** Add execution cells below to:\n",
    "\n",
    "1. **Prepare aggregated data** (daily crime counts by NPU)\n",
    "2. **Run baseline models** (Seasonal Naive 1d, 7d, Historical Mean)\n",
    "3. **Run ML models** (XGBoost, CatBoost, LightGBM with Poisson objective)\n",
    "4. **Compare results** across all models\n",
    "\n",
    "**Example execution code:**\n",
    "```python\n",
    "# Aggregate to daily NPU level\n",
    "daily_npu = df.groupby(['npu', df['report_date'].dt.date]).size().reset_index(name='crime_count')\n",
    "daily_npu = daily_npu.rename(columns={'report_date': 'date'})\n",
    "daily_npu['report_date'] = pd.to_datetime(daily_npu['date'])\n",
    "\n",
    "# Add temporal features\n",
    "daily_npu['day_of_week'] = daily_npu['report_date'].dt.dayofweek\n",
    "daily_npu['month'] = daily_npu['report_date'].dt.month\n",
    "daily_npu['is_weekend'] = daily_npu['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Run baseline\n",
    "naive_1d = SeasonalNaive(period=1)\n",
    "results_1d, preds_1d = run_rolling_cv(naive_1d, daily_npu)\n",
    "\n",
    "# Run XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "xgb_model = XGBRegressor(objective='count:poisson', n_estimators=100, random_state=42)\n",
    "results_xgb, preds_xgb = run_rolling_cv(xgb_model, daily_npu)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c146c53",
   "metadata": {},
   "source": [
    "## ‚úÖ Model Selection & Deployment\n",
    "\n",
    "**Best performing model:** [To be filled after running]\n",
    "\n",
    "**Next steps:**\n",
    "1. Review error analysis - which NPUs/times have highest errors?\n",
    "2. Consider ensemble methods (averaging top 3 models)\n",
    "3. Deploy best model for real-time predictions\n",
    "4. Set up monitoring dashboard\n",
    "\n",
    "**Results location:** `data/processed/apd/cv_results/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa09bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Final Summary ===========================================================\n",
    "console.print(\"\\n[bold magenta]‚ïê‚ïê‚ïê Model T Setup Complete ‚ïê‚ïê‚ïê[/bold magenta]\\n\")\n",
    "\n",
    "setup_summary = {\n",
    "    \"Data Loaded\": f\"{len(df):,} records\",\n",
    "    \"CV Framework\": \"4-fold rolling origin (2022-2024)\",\n",
    "    \"Baseline Models\": \"Seasonal Naive (1d, 7d), Historical Mean\",\n",
    "    \"ML Models\": \"XGBoost, CatBoost, LightGBM (Poisson)\",\n",
    "    \"Output Directory\": str(CV_RESULTS_DIR),\n",
    "}\n",
    "\n",
    "setup_table = Table(show_header=False, show_lines=True)\n",
    "setup_table.add_column(\"Component\", style=\"cyan\")\n",
    "setup_table.add_column(\"Status\", style=\"green\")\n",
    "\n",
    "for component, status in setup_summary.items():\n",
    "    setup_table.add_row(component, status)\n",
    "\n",
    "console.print(setup_table)\n",
    "console.print(f\"\\n[bold green]‚úì 03_modelt.ipynb setup complete![/bold green]\")\n",
    "console.print(f\"[yellow]Ready to run models! Add execution cells in Section 3.[/yellow]\")\n",
    "\n",
    "show_pipeline_table()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
